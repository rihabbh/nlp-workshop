{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importer les librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install numpy \n",
    "#! pip install pandas \n",
    "#! pip install matplotlib \n",
    "#! pip install plotly \n",
    "#! pip install nltk \n",
    "#! pip install textblob \n",
    "#! pip install wordcloud \n",
    "#! pip install scikit-learn\n",
    "#! pip install sklearn \n",
    "#! pip install openpyxl\n",
    "#! pip install nbformat==4.2.0\n",
    "#! python -m textblob.download_corpora\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Libraries üìö\n",
    "# --------------------------------------\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Plot library üìä\n",
    "# --------------------------------------\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objs as go\n",
    "import plotly.io as pio\n",
    "\n",
    "\n",
    "#¬†NLP\n",
    "# --------------------------------------\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from textblob import Word, TextBlob\n",
    "from wordcloud import WordCloud  #¬†visualization of words\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "\n",
    "# Metrics üìê\n",
    "# --------------------------------------\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, cross_validate\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "# Machine Learning Models ü§ñ\n",
    "# --------------------------------------\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "# Customize to Remove Warnings and Better Observation üîß\n",
    "# --------------------------------------------------------\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 200)\n",
    "pd.set_option('display.float_format', lambda x: '%.2f' % x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probl√®matique\n",
    "\n",
    "Augmenter ses ventes en analysant les commentaires re√ßus sur des produits, et am√©liorer leurs caract√©ristiques en fonction des plaintes re√ßues. Conform√©ment √† cet objectif, les commentaires seront √©tiquet√©s en effectuant une analyse des sentiments et un mod√®le de classification sera cr√©√© avec les donn√©es √©tiquet√©es.\n",
    "\n",
    "### Les donn√©es\n",
    "\n",
    "L'ensemble de donn√©es comprend les commentaires faits pour un certain groupe de produits, le titre du commentaire, le nombre d'√©toiles et les variables qui indiquent combien de personnes ont trouv√© le commentaire utile.\n",
    "\n",
    "### Import du dataset :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Star</th>\n",
       "      <th>HelpFul</th>\n",
       "      <th>Title</th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>looks great</td>\n",
       "      <td>Happy with it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>Pattern did not align between the two panels.</td>\n",
       "      <td>Good quality material however the panels are m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>Imagery is stretched. Still fun.</td>\n",
       "      <td>Product was fun for bedroom windows.&lt;br /&gt;Imag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>Que se ven elegantes muy finas</td>\n",
       "      <td>Lo unico que me gustaria es que sean un poco ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>Wow great purchase</td>\n",
       "      <td>Great bang for the buck I can't believe the qu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>Not for us</td>\n",
       "      <td>Looks different then photo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>Perfect for spa room</td>\n",
       "      <td>Was exactly what i was looking for. Heavy mate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>Actually better than expected</td>\n",
       "      <td>Looking at the picture, I thought these curtai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Not what expected</td>\n",
       "      <td>Much whiter than I thought it would be and was...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>Pretty as a Picture</td>\n",
       "      <td>These are curtains just as the picture shows. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>The best Christmas decoration I think I have e...</td>\n",
       "      <td>It blocks views from our living room and front...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>The door images are crooked and rustic. Messes...</td>\n",
       "      <td>They are private when closed. Darkening to a p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>They weren‚Äôt  blackout curtains</td>\n",
       "      <td>They don‚Äôt block out light</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Too sheer</td>\n",
       "      <td>Work fine for night curtains but to sheer for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>They are pretty, sort of satiny curtains that ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Star  HelpFul                                              Title                                             Review\n",
       "0      5        0                                        looks great                                      Happy with it\n",
       "1      5        0      Pattern did not align between the two panels.  Good quality material however the panels are m...\n",
       "2      5        0                   Imagery is stretched. Still fun.  Product was fun for bedroom windows.<br />Imag...\n",
       "3      5        0                     Que se ven elegantes muy finas   Lo unico que me gustaria es que sean un poco ...\n",
       "4      5        0                                 Wow great purchase  Great bang for the buck I can't believe the qu...\n",
       "5      5        0                                         Not for us                         Looks different then photo\n",
       "6      5        0                               Perfect for spa room  Was exactly what i was looking for. Heavy mate...\n",
       "7      5        0                      Actually better than expected  Looking at the picture, I thought these curtai...\n",
       "8      4        0                                  Not what expected  Much whiter than I thought it would be and was...\n",
       "9      5        0                                Pretty as a Picture  These are curtains just as the picture shows. ...\n",
       "10     5        0  The best Christmas decoration I think I have e...  It blocks views from our living room and front...\n",
       "11     4        0  The door images are crooked and rustic. Messes...  They are private when closed. Darkening to a p...\n",
       "12     5        0                    They weren‚Äôt  blackout curtains                         They don‚Äôt block out light\n",
       "13     4        0                                          Too sheer  Work fine for night curtains but to sheer for ...\n",
       "14     5        0  They are pretty, sort of satiny curtains that ...                                                   "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel(\"amazon.xlsx\")\n",
    "df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Il y a 18 avis sans commentaire(s)\n"
     ]
    }
   ],
   "source": [
    "### Commencez par supprimer les reviews sans commentaire\n",
    "### utilisez la fonction dropna de pandas\n",
    "print(\"Il y a\",df['Review'].isnull().sum(),\"avis sans commentaire(s)\")\n",
    "xxx\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pr√© Traitement du texte\n",
    "\n",
    "### Mettez tous les charact√®res en minuscule\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Utilisez la fonction .str.lower() de pandas\n",
    "xxx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ponctuation\n",
    "\n",
    "Tout comme les majuscules et les minuscules, les signes de ponctuation ne contiennent pas de valeur de mesure. Par exemple, si nous pensons que nous faisons un exemple de classification, il y a 2 avis, l'un d'eux a beaucoup plus de points/virgules. Dans cette situation, nous n'attendons AUCUN mod√®le des ponctuations. Bien qu'il s'agisse de l'approche courante, elle peut varier en fonction du probl√®me.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Supprimez toute forme de ponctuation par un espace\n",
    "### Utilisez la fonction .str.replace() de pandas et les expressions r√©guli√®res ! \n",
    "xxx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chiffres\n",
    "\n",
    "RAPPEL :\n",
    "Comme ci-dessus, notre probl√©matique peut avoir une discrimination sur les nombres. Par exemple, inclure beaucoup ou moins de nombres peut √™tre crucial pour le probl√®me. Dans ce type de probl√®me, la suppression des nombres n'est pas une m√©thode √† utiliser. Dans notre exemple, nous supprimons les nombres car ils ne sont pas significatifs.\n",
    "\n",
    "L'approche g√©n√©rale consiste √† supprimer toutes les structures probl√©matiques en dehors du texte. Par exemple, lorsqu'il y a des donn√©es de m√©dias sociaux, nous pouvons choisir de supprimer les √©mojis, les liens de pages, etc.\n",
    "\n",
    "Ici, Nous d√©tectons les chiffres via une expression r√©guli√®re. \\d nous aide √† capturer les chiffres.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "### M√™me chose que la derni√®re cellules\n",
    "xxx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balises HTML\n",
    "\n",
    "Ils y a des balises HTML dans certains commentaires, avant d'√©liminer les caract√®res sp√©ciaux, assurons nous d'enlever ces balises d'abord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Utiliser la librairie re\n",
    "CLEANR = re.compile('<.*?>') \n",
    "xxxx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Caract√®re sp√©ciaux\n",
    "\n",
    "Maintenant la m√™me chose avec tout les caract√®res sp√©ciaux."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Indice : [^a-zA-Z0-9]\n",
    "xxxxxx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stopword\n",
    "\n",
    "Les mots couramment utilis√©s dans la langue n'ont pas de mesure. Des expressions telles que diverses conjonctions telles que est, pour, ceci ou divers pronoms n'ont pas de signification m√©trique. Par cons√©quent, nous supprimerons ces expressions.\n",
    "\n",
    "Nous devons t√©l√©charger ¬´ stopwords ¬ª de la biblioth√®que nltk. Il a √©t√© pr√©par√© pour l'anglais, il existe √©galement des √©tudes pour d'autres langues. Par cons√©quent, vous pouvez utiliser la langue que vous souhaitez comme argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading stopwords: <urlopen error [Errno 11001]\n",
      "[nltk_data]     getaddrinfo failed>\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "sw = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                Happy\n",
       "1    Good quality material however panels mis-matched.\n",
       "2    Product fun bedroom windows.<br />Imagery bit ...\n",
       "3    Lo unico que gustaria es que sean un poco mas ...\n",
       "4    Great bang buck I can't believe quality materi...\n",
       "Name: Review, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Completez le xxxxx\n",
    "df['Review'] = df['Review'].apply(lambda x: \" \".join(x for x in str(x).split() if x not in xxxxx))\n",
    "df['Review'].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "#### Completez le xxxxx\n",
    "\n",
    "df['Review'] = df['Review'].apply(lambda x: \" \".join([Word(word).lemmatize() for word in xxxxxx]))\n",
    "\n",
    "df['Review'].head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation\n",
    "\n",
    "\n",
    "### Fr√©quence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Happy</td>\n",
       "      <td>11.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good</td>\n",
       "      <td>106.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>quality</td>\n",
       "      <td>563.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>material</td>\n",
       "      <td>361.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>however</td>\n",
       "      <td>27.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>panels</td>\n",
       "      <td>87.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>mis-matched.</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Product</td>\n",
       "      <td>18.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>fun</td>\n",
       "      <td>42.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>bedroom</td>\n",
       "      <td>96.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          index      0\n",
       "0         Happy  11.00\n",
       "1          Good 106.00\n",
       "2       quality 563.00\n",
       "3      material 361.00\n",
       "4       however  27.00\n",
       "5        panels  87.00\n",
       "6  mis-matched.   1.00\n",
       "7       Product  18.00\n",
       "8           fun  42.00\n",
       "9       bedroom  96.00"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract the term frequencies(frequency of the words) and create a df\n",
    "tf = df[\"Review\"].apply(lambda x: pd.value_counts(x.split(\" \"))).sum(axis=0).reset_index()\n",
    "tf.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>tf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>I</td>\n",
       "      <td>4413.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>curtains</td>\n",
       "      <td>1203.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>The</td>\n",
       "      <td>1070.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>like</td>\n",
       "      <td>987.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>love</td>\n",
       "      <td>788.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11991</th>\n",
       "      <td>static</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11992</th>\n",
       "      <td>collect</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12008</th>\n",
       "      <td>unfortunately.</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12007</th>\n",
       "      <td>mane</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12006</th>\n",
       "      <td>hours.</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12025 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                words      tf\n",
       "19                  I 4413.00\n",
       "60           curtains 1203.00\n",
       "72                The 1070.00\n",
       "214              like  987.00\n",
       "150              love  788.00\n",
       "...               ...     ...\n",
       "11991          static    1.00\n",
       "11992         collect    1.00\n",
       "12008  unfortunately.    1.00\n",
       "12007            mane    1.00\n",
       "12006          hours.    1.00\n",
       "\n",
       "[12025 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fix the column names\n",
    "tf.columns = [\"words\", \"tf\"]  \n",
    "\n",
    "# to see the most frequent words\n",
    "tf.sort_values(\"tf\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Plot 1\n",
    "xxxxxxxxx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Plot 2\n",
    "xxxxxxxxxxxxxxx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse de sentiments\n",
    "\n",
    "Cette section sera divis√©e en 2 parties. La premi√®re partie explique les m√©thodes et comment utiliser l'analyse des sentiments. La deuxi√®me partie concerne la mise en ≈ìuvre de l'analyse des sentiments dans notre ensemble de donn√©es.\n",
    "\n",
    "L'analyse des sentiments vise √† exprimer l'√©tat √©motionnel des textes de mani√®re math√©matique. Supposons que nous ayons une phrase, chaque mot qui la compose a une signification positive/n√©gative/neutre. Ces significations sont √©valu√©es de mani√®re holistique et des √©valuations sont faites pour d√©terminer si un texte est positif ou n√©gatif.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading vader_lexicon: <urlopen error [Errno 11001]\n",
      "[nltk_data]     getaddrinfo failed>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('vader_lexicon')  # pre-trained model for sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.0, 'neu': 0.423, 'pos': 0.577, 'compound': 0.6249}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#¬†Example 1\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "sia.polarity_scores(\"The film was awesome\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.207, 'neu': 0.666, 'pos': 0.127, 'compound': -0.298}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#¬†Example 2\n",
    "sia.polarity_scores(\"I liked this music but it is not good as the other one\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Pour chaque avis, ajouter une colonne 'compound' du score compound dans le dataset\n",
    "xxxxxx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Ajoutez une colonne 'Polarity Scores' √©gale 'pos' si le compound est super √† zero sinon 'neg' \n",
    "xxxxxx\n",
    "df[\"Polarity Scores\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"Polarity Scores\")[\"Star\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons maintenant d√©velopper notre propre mod√®le d'analyse des sentiments "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Polarity Scores\"] = LabelEncoder().fit_transform(df[\"Polarity Scores\"])\n",
    "y = df[\"Polarity Scores\"]\n",
    "X = df[\"Review\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\" X \".center(50, \"~\"))\n",
    "display(X.head())\n",
    "print(\"\")\n",
    "print(\" Y \".center(50, \"~\"))\n",
    "display(y.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En d'autres termes, nous devons effectuer de telles op√©rations sur X afin de pouvoir le mettre dans un format mesurable, sur lequel des op√©rations math√©matiques et une mod√©lisation par apprentissage automatique peuvent √™tre effectu√©es. Pour cela, nous devons cr√©er des vecteurs de mots. M√©thodes couramment utilis√©es :\n",
    "\n",
    "- Count Vectors\n",
    "- TF-IDF\n",
    "- Autres m√©thodes d'incorporation de mots (Word2Vec, GloVe, BERT, etc.)\n",
    "\n",
    "Nous analyserons l'impl√©mentation de Count Vectors et TF-IDF. D'autres m√©thodes d'incorporation de mots peuvent √™tre recherch√©es et appliqu√©es avec un pr√©traitement similaire (comme la suppression des ponctuations, des nombres, etc.). Chacune de ces m√©thodes est la m√©thode utilis√©e par l'ordinateur pour mettre ces textes dans des op√©rations math√©matiques dans le monde de l'alg√®bre lin√©aire. Le texte que j'ai est sous la forme d'un texte et je dois faire quelque chose avec ce texte pour qu'il puisse √™tre trait√© dans le monde de l'alg√®bre lin√©aire. Commen√ßons par l'explication des m√©thodes et l'application sur notre ensemble de donn√©es.\n",
    "\n",
    "## Count Vector "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WordList(['ngram', 'is', 'a']),\n",
       " WordList(['is', 'a', 'contiguous']),\n",
       " WordList(['a', 'contiguous', 'sequence']),\n",
       " WordList(['contiguous', 'sequence', 'of']),\n",
       " WordList(['sequence', 'of', 'n']),\n",
       " WordList(['of', 'n', 'items']),\n",
       " WordList(['n', 'items', 'from']),\n",
       " WordList(['items', 'from', 'a']),\n",
       " WordList(['from', 'a', 'given']),\n",
       " WordList(['a', 'given', 'sample']),\n",
       " WordList(['given', 'sample', 'of']),\n",
       " WordList(['sample', 'of', 'text']),\n",
       " WordList(['of', 'text', 'or']),\n",
       " WordList(['text', 'or', 'speech'])]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = \"\"\"ngram is a contiguous sequence of n items from a given sample of text or speech.\"\"\"\n",
    "\n",
    "TextBlob(a).ngrams(3)  # For example, let's create a triple ngram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['and this', 'document is', 'first document', 'is the', 'is this',\n",
       "       'second document', 'the first', 'the second', 'the third',\n",
       "       'third one', 'this document', 'this is', 'this the'], dtype=object)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = ['This is the first document.',\n",
    "          'This document is the second document.',\n",
    "          'And this is the third one.',\n",
    "          'Is this the first document?']\n",
    "# word frequency\n",
    "vectorizer = CountVectorizer(analyzer='word', ngram_range=(2, 2))\n",
    "X_c = vectorizer.fit_transform(corpus)  # we transformed the corpus with fit_transform\n",
    "vectorizer.get_feature_names_out()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0],\n",
       "       [1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0],\n",
       "       [0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_c.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Appliquer cette m√©thode √† notre ensemble X\n",
    "xxxxxx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### word frequency\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.46979139, 0.58028582, 0.38408524, 0.        ,\n",
       "        0.        , 0.38408524, 0.        , 0.38408524],\n",
       "       [0.        , 0.6876236 , 0.        , 0.28108867, 0.        ,\n",
       "        0.53864762, 0.28108867, 0.        , 0.28108867],\n",
       "       [0.51184851, 0.        , 0.        , 0.26710379, 0.51184851,\n",
       "        0.        , 0.26710379, 0.51184851, 0.26710379],\n",
       "       [0.        , 0.46979139, 0.58028582, 0.38408524, 0.        ,\n",
       "        0.        , 0.38408524, 0.        , 0.38408524]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_word_vectorizer = TfidfVectorizer()  # default = word frequency\n",
    "corpus_tf_idf_word = tf_idf_word_vectorizer.fit_transform(corpus)\n",
    "tf_idf_word_vectorizer.get_feature_names_out()\n",
    "corpus_tf_idf_word.toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Appliquer cette m√©thode √† notre ensemble X\n",
    "xxxxxx\n",
    "X_tf_idf_word = xxxx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Vous pouvez aussi utilisez cette m√©thode avec des ngram\n",
    "### en mettant en param√©tre de TfidfVectorizer()  ngram_range=(2, 3)\n",
    "\n",
    "xxxxxx\n",
    "X_tf_idf_ngram = xxxx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression logistique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Words with TF-IDF\n",
    "log_model = LogisticRegression().fit(X_tf_idf_word, y)\n",
    "cross_val_score(log_model,\n",
    "                X_tf_idf_word,\n",
    "                y,\n",
    "                scoring=\"accuracy\",\n",
    "                cv=5).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_review = pd.Series(\"this product is great\")\n",
    "\n",
    "# Utilisez le mod√®le log_model que vous venez de g√©n√©rer pour classer ce nouvel avis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's pick a sample comment from the original dataset and ask it to the model\n",
    "sample = df[\"Review\"].sample(1).values\n",
    "print(sample)\n",
    "random_review = pd.Series(sample)\n",
    "new_review = TfidfVectorizer().fit(X).transform(random_review)\n",
    "log_model.predict(new_review)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forrest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count Vectors\n",
    "rf_model = RandomForestClassifier().fit(X_c, y)\n",
    "print(\"Count Vectors Score\", cross_val_score(rf_model, X_c, y, cv=5, n_jobs=-1).mean()) \n",
    "\n",
    "# TF-IDF Word-Level\n",
    "rf_model = RandomForestClassifier().fit(X_tf_idf_word, y)\n",
    "print(\"TF-IDF Word-Level Score\", cross_val_score(rf_model, X_tf_idf_word, y, cv=5, n_jobs=-1).mean())\n",
    "\n",
    "# TF-IDF N-Gram\n",
    "rf_model = RandomForestClassifier().fit(X_tf_idf_ngram, y)\n",
    "print(\"TF-IDF N-Gram Score\", cross_val_score(rf_model, X_tf_idf_ngram, y, cv=5, n_jobs=-1).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Utilisez le dernier mod√®le pour classifier une review que vous avez cr√©er (en anglais bien s√ªr)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
